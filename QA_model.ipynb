{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "2bB3MZnaPMzh"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArijaK/QuestionAnswering/blob/main/QA_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question Answering Model**\n",
        "\n",
        "The code below (data preparation and evaluation) is based on Hugging Face *Question answering* examples, availabe [here (chapter)](https://huggingface.co/learn/nlp-course/chapter7/7?fw=pt) and [here (notebook)](https://github.com/huggingface/notebooks/blob/main/examples/question_answering.ipynb).\n",
        "\n"
      ],
      "metadata": {
        "id": "tFK-I144_hN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "id": "EtKtEAx7QLHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flags.\n",
        "# Data preprocessing.\n",
        "DATASET = 'squad_v2'\n",
        "MODEL_CHECKPOINT = 'albert-base-v2'\n",
        "# Maximum length of a feature (question and context).\n",
        "MAX_LENGTH = 384\n",
        "# Number of overlapping tokens.\n",
        "STRIDE = 128\n",
        "# Fine-tuning.\n",
        "TRAIN = False\n",
        "# Evaluation.\n",
        "N_BEST = 50\n",
        "# Usually sentences do not exceed this length.\n",
        "MAX_ANSWER_LENGTH = 40\n",
        "# Path to fine-tuned model.\n",
        "USE_SAVED = True\n",
        "MODEL_PATH = 'drive/MyDrive/Colab Notebooks/Fine-tuned_models/albert-base-v2-squadv2'"
      ],
      "metadata": {
        "id": "nafn_dQy0lc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation"
      ],
      "metadata": {
        "id": "2bB3MZnaPMzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Easy way to load the dataset.\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(DATASET)\n",
        "dataset"
      ],
      "metadata": {
        "id": "cjWZV2frx8YH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24444292-ddc0-467b-d63b-33841c8bdcb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 130319\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 11873\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing.\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)"
      ],
      "metadata": {
        "id": "4-hMCQB44cN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if a fast tokenizer is implemented.\n",
        "assert tokenizer.is_fast"
      ],
      "metadata": {
        "id": "Y5mF2cathDwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the tokenizer on a simple example.\n",
        "inputs = tokenizer('Where can I buy cat food?', 'Cat food is sold in all pet stores. You can buy cat food online too.')\n",
        "tokenizer.decode(inputs['input_ids'])"
      ],
      "metadata": {
        "id": "doHPtjGA9mNh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe35ed23-4492-4b87-90ea-714f3ef5dc72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] where can i buy cat food?[SEP] cat food is sold in all pet stores. you can buy cat food online too.[SEP]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_train_data(data):\n",
        "  # Remove leading and trailing whitespaces.\n",
        "  data['question'] = [q.strip() for q in data['question']]\n",
        "\n",
        "  inputs = tokenizer(\n",
        "      data['question'],\n",
        "      data['context'],\n",
        "      truncation='only_second',\n",
        "      max_length=MAX_LENGTH,\n",
        "      stride=STRIDE,\n",
        "      return_overflowing_tokens=True,\n",
        "      return_offsets_mapping=True,\n",
        "      padding='max_length',\n",
        "  )\n",
        "\n",
        "  # Map from a feature to its corresponding dataset sample.\n",
        "  sample_mapping = inputs.pop('overflow_to_sample_mapping')\n",
        "  # Map from token to character position in the original context.\n",
        "  offset_mapping = inputs.pop('offset_mapping')\n",
        "\n",
        "  inputs['start_positions'] = []\n",
        "  inputs['end_positions'] = []\n",
        "\n",
        "  for i, offsets in enumerate(offset_mapping):\n",
        "    input_ids = inputs['input_ids'][i]\n",
        "    # For no answer.\n",
        "    cls_index = input_ids.index(tokenizer.cls_token_id)\n",
        "\n",
        "    sequence_ids = inputs.sequence_ids(i)\n",
        "    sample_index = sample_mapping[i]\n",
        "    answer = data['answers'][sample_index]\n",
        "\n",
        "    if len(answer['answer_start']) == 0:\n",
        "      inputs['start_positions'].append(cls_index)\n",
        "      inputs['end_positions'].append(cls_index)\n",
        "    else:\n",
        "      start_char = answer['answer_start'][0]\n",
        "      end_char = start_char + len(answer['text'][0])\n",
        "\n",
        "      # Find the start and end of the current feature's context in the sample text.\n",
        "      token_start_index = 0\n",
        "      while sequence_ids[token_start_index] != 1:\n",
        "        token_start_index += 1\n",
        "\n",
        "      token_end_index = len(input_ids) - 1\n",
        "      while sequence_ids[token_end_index] != 1:\n",
        "        token_end_index -= 1\n",
        "\n",
        "      # If the answer is out of the current feature's context.\n",
        "      if not(offsets[token_start_index][0] <= start_char and\n",
        "             offsets[token_end_index][1] >= end_char):\n",
        "        inputs['start_positions'].append(cls_index)\n",
        "        inputs['end_positions'].append(cls_index)\n",
        "      else:\n",
        "        # Find tokens that correspond to the start and end of the answer.\n",
        "        while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
        "          token_start_index += 1\n",
        "        inputs['start_positions'].append(token_start_index - 1)\n",
        "        while offsets[token_end_index][1] >= end_char:\n",
        "          token_end_index -= 1\n",
        "        inputs['end_positions'].append(token_end_index + 1)\n",
        "\n",
        "  return inputs"
      ],
      "metadata": {
        "id": "UqafycX5Bxxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if function works as expected.\n",
        "result = preprocess_train_data(dataset['train'][:1])\n",
        "print(tokenizer.decode(result['input_ids'][0][result['start_positions'][0]: result['end_positions'][0]+1]))\n",
        "print(dataset['train'][0]['answers']['text'][0])"
      ],
      "metadata": {
        "id": "tMi1pre0kLXi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53ffce50-5a48-47f9-9058-550a0b2df666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in the late 1990s\n",
            "in the late 1990s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = dataset['train'].map(\n",
        "    preprocess_train_data,\n",
        "    batched=True,\n",
        "    remove_columns=dataset['train'].column_names,\n",
        ")\n",
        "len(dataset['train']), len(tokenized_dataset)"
      ],
      "metadata": {
        "id": "vHcv1wbUSnwy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe2189d6-44d2-4a31-d528-db1afef27bd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(130319, 131958)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing.\n",
        "def preprocess_validation_data(data):\n",
        "  data['question'] = [q.strip() for q in data['question']]\n",
        "\n",
        "  inputs = tokenizer(\n",
        "      data['question'],\n",
        "      data['context'],\n",
        "      truncation='only_second',\n",
        "      max_length=MAX_LENGTH,\n",
        "      stride=STRIDE,\n",
        "      return_overflowing_tokens=True,\n",
        "      return_offsets_mapping=True,\n",
        "      padding='max_length',\n",
        "  )\n",
        "\n",
        "  # Map from a feature to its corresponding dataset sample.\n",
        "  sample_mapping = inputs.pop('overflow_to_sample_mapping')\n",
        "  inputs['example_ids'] = []\n",
        "\n",
        "  for i in range(len(inputs['input_ids'])):\n",
        "    sample_index = sample_mapping[i]\n",
        "    inputs['example_ids'].append(data['id'][sample_index])\n",
        "\n",
        "    # Set the question part offsets to None, to easily determine the context part.\n",
        "    sequence_ids = inputs.sequence_ids(i)\n",
        "    inputs['offset_mapping'][i] = [\n",
        "        (o if sequence_ids[k] == 1 else None)\n",
        "        for k, o in enumerate(inputs['offset_mapping'][i])\n",
        "    ]\n",
        "\n",
        "  return inputs"
      ],
      "metadata": {
        "id": "-P_VXBdGugPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_dataset = dataset['validation'].map(\n",
        "    preprocess_validation_data,\n",
        "    batched=True,\n",
        "    remove_columns=dataset['validation'].column_names,\n",
        ")\n",
        "len(dataset['validation']), len(validation_dataset)"
      ],
      "metadata": {
        "id": "hjhmNM-MLEMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b68b3d54-4419-4e89-d40c-0a40c5bc293f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11873, 12171)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning\n",
        "\n",
        "Our fine-tuned models can be found in Google Drive shared folder [here](https://drive.google.com/drive/folders/1LjE8UzVeHCNoYPd6U9t-OrV2EDBeqR8W?usp=sharing)."
      ],
      "metadata": {
        "id": "fdi_MkNtX7DB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "SBazHdROmsje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "nndUgR0qBx8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments, AutoModelForQuestionAnswering\n",
        "\n",
        "# Use already fine-tuned models instead of fine-tuning one.\n",
        "if USE_SAVED:\n",
        "  model = model = AutoModelForQuestionAnswering.from_pretrained(MODEL_PATH)\n",
        "else:\n",
        "  model = AutoModelForQuestionAnswering.from_pretrained(MODEL_CHECKPOINT)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    fp16=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model.to(device),\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    eval_dataset=validation_dataset,\n",
        ")"
      ],
      "metadata": {
        "id": "Mq6b9zjHYAGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if TRAIN:\n",
        "  trainer.train()"
      ],
      "metadata": {
        "id": "NCfb_vA-YDnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if TRAIN:\n",
        "  trainer.save_model(MODEL_CHECKPOINT+'-squadv2')"
      ],
      "metadata": {
        "id": "ona_D_t8Z9nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "WGqLuKUtuIKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_predictions = trainer.predict(validation_dataset)"
      ],
      "metadata": {
        "id": "MGLGslSVheri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get back `example_ids` and `offset_mapping` column.\n",
        "validation_dataset.set_format(type=validation_dataset.format['type'], columns=list(validation_dataset.features.keys()))"
      ],
      "metadata": {
        "id": "ylY3JYFt0GZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def postprocess_predictions(raw_predictions, features, examples):\n",
        "  all_start_logits, all_end_logits = raw_predictions\n",
        "  features_per_example = collections.defaultdict(list)\n",
        "  for i, feature in enumerate(features):\n",
        "    features_per_example[feature['example_ids']].append(i)\n",
        "\n",
        "  predictions = collections.OrderedDict()\n",
        "  for example in tqdm(examples):\n",
        "    example_id = example['id']\n",
        "    context = example['context']\n",
        "\n",
        "    # Score of the impossible answer for the example.\n",
        "    min_null_score = None\n",
        "    answers = []\n",
        "\n",
        "    for feature_index in features_per_example[example_id]:\n",
        "      start_logit = all_start_logits[feature_index]\n",
        "      end_logit = all_end_logits[feature_index]\n",
        "      offset_mapping = features[feature_index]['offset_mapping']\n",
        "\n",
        "      cls_index = features[feature_index]['input_ids'].index(tokenizer.cls_token_id)\n",
        "      feature_null_score = start_logit[cls_index] + end_logit[cls_index]\n",
        "\n",
        "      if min_null_score is None or min_null_score < feature_null_score:\n",
        "        min_null_score = feature_null_score\n",
        "\n",
        "      start_indexes = np.argsort(start_logit)[-1: -N_BEST - 1 : -1].tolist()\n",
        "      end_indexes = np.argsort(end_logit)[-1: -N_BEST - 1 : -1].tolist()\n",
        "      for start_index in start_indexes:\n",
        "        for end_index in end_indexes:\n",
        "          if (start_index >= len(offset_mapping)\n",
        "              or end_index >= len(offset_mapping)\n",
        "              or offset_mapping[start_index] is None\n",
        "              or offset_mapping[end_index] is None\n",
        "          ):\n",
        "            continue\n",
        "          if end_index < start_index or end_index-start_index+1>MAX_ANSWER_LENGTH:\n",
        "            continue\n",
        "\n",
        "          start_char = offset_mapping[start_index][0]\n",
        "          end_char = offset_mapping[end_index][1]\n",
        "          answers.append({\n",
        "              'text': context[start_char : end_char],\n",
        "              'logit_score': start_logit[start_index] + end_logit[end_index],\n",
        "          })\n",
        "\n",
        "    if len(answers) > 0:\n",
        "      best_answer = max(answers, key=lambda x: x['logit_score'])\n",
        "    else:\n",
        "      best_answer = {'text': '', 'logit_score': 0.0}\n",
        "\n",
        "    answer = best_answer['text'] if best_answer['logit_score'] > min_null_score else ''\n",
        "    predictions[example_id] = answer\n",
        "\n",
        "  return predictions\n"
      ],
      "metadata": {
        "id": "tpp1TirLaWdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = postprocess_predictions(raw_predictions.predictions, validation_dataset, dataset['validation'])"
      ],
      "metadata": {
        "id": "qNxVq1_WqN4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Save predictions as json file.\n",
        "with open(\"predictions.json\", \"w\") as json_file:\n",
        "    json.dump(predictions, json_file)"
      ],
      "metadata": {
        "id": "sdHu_TFD0uq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "metric = load_metric(DATASET, trust_remote_code=True)\n",
        "formatted_predictions = [{'id': k, 'prediction_text': v, 'no_answer_probability': 0.0} for k, v in predictions.items()]\n",
        "theoretical_answers = [{'id': ex['id'], 'answers': ex['answers']} for ex in dataset['validation']]\n",
        "metric.compute(predictions=formatted_predictions, references=theoretical_answers)"
      ],
      "metadata": {
        "id": "rost4nPAtF7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "VXmUvENmQRtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "CMOe-QUCpewq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_question(question, context, model):\n",
        "    inputs = tokenizer(question, context, return_tensors='pt', truncation=True, max_length=512)\n",
        "\n",
        "    outputs = model(**inputs.to(device))\n",
        "\n",
        "    # Get the most likely start and end tokens\n",
        "    start_scores = outputs.start_logits\n",
        "    end_scores = outputs.end_logits\n",
        "    start_index = torch.argmax(start_scores)\n",
        "    end_index = torch.argmax(end_scores) + 1\n",
        "\n",
        "    # Get score for no answer case\n",
        "    no_answer_score = start_scores[0][0].item() + end_scores[0][0].item()\n",
        "\n",
        "    # Check if the predicted span is valid and is not no answer case\n",
        "    max_start_score = start_scores[0][start_index].item()\n",
        "    max_end_score = end_scores[0][end_index - 1].item()\n",
        "    if start_index < len(inputs.input_ids[0]) and end_index <= len(inputs.input_ids[0]) and (max_start_score + max_end_score) > no_answer_score:\n",
        "        answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs.input_ids[0][start_index:end_index]))\n",
        "    else:\n",
        "        answer = \"No answer\"\n",
        "\n",
        "    return answer"
      ],
      "metadata": {
        "id": "YO5e--khm8OZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# some test cases for demonstration\n",
        "test_cases = [\n",
        "    {\n",
        "        \"context\": \"The Eiffel Tower is located in Paris.\",\n",
        "        \"question\": \"Where is the Eiffel Tower located?\",\n",
        "        \"expected_answer\": \"Paris\"\n",
        "    },\n",
        "    {\n",
        "        \"context\": \"Albert Einstein developed the theory of relativity.\",\n",
        "        \"question\": \"Who developed the theory of relativity?\",\n",
        "        \"expected_answer\": \"Albert Einstein\"\n",
        "    },\n",
        "    {\n",
        "        \"context\": \"The Declaration of Independence was signed in 1776.\",\n",
        "        \"question\": \"When was the Declaration of Independence signed?\",\n",
        "        \"expected_answer\": \"1776\"\n",
        "    },\n",
        "    {\n",
        "        \"context\": \"Water boils at 100 degrees Celsius.\",\n",
        "        \"question\": \"What is the capital of Australia?\",\n",
        "        \"expected_answer\": \"No answer\"\n",
        "    },\n",
        "    {\n",
        "        \"context\": \"The Great Wall of China is a series of fortifications that were built across the northern borders of China to protect and consolidate territories of Chinese states and empires against various nomadic groups of the steppe and their polities. Several walls were being built as early as the 7th century BC; these, later joined together and made bigger and stronger, are now collectively referred to as the Great Wall.\",\n",
        "        \"question\": \"Where is the Great Wall located?\",\n",
        "        \"expected_answer\": \"7th century BC\"\n",
        "    },\n",
        "    {\n",
        "        \"context\": \"Despite being a well-known physicist, Isaac Newton also made significant contributions to mathematics, including the development of calculus.\",\n",
        "        \"question\": \"What did Isaac Newton develop in mathematics?\",\n",
        "        \"expected_answer\": \"calculus\"\n",
        "    },\n",
        "    {\n",
        "        \"context\": \"Amazon was founded by Jeff Bezos in 1994. Initially started as an online bookstore, it has since expanded to a wide variety of products and services.\",\n",
        "        \"question\": \"Who founded Amazon?\",\n",
        "        \"expected_answer\": \"Jeff Bezos\"\n",
        "    },\n",
        "    {\n",
        "        \"context\": \"Marie Curie was a physicist and chemist who conducted pioneering research on radioactivity. She was the first woman to win a Nobel Prize.\",\n",
        "        \"question\": \"Who was the first woman to win a Nobel Prize?\",\n",
        "        \"expected_answer\": \"Marie Curie\"\n",
        "    },\n",
        "    {\n",
        "        \"context\": \"Paris is a major European city and a global center for art, fashion, gastronomy, and culture. It is the capital of France.\",\n",
        "        \"question\": \"What is Paris known for?\",\n",
        "        \"expected_answer\": \"art, fashion, gastronomy, and culture\"\n",
        "    },\n",
        "    {\n",
        "        \"context\": \"Mount Everest is 8,848 meters tall.\",\n",
        "        \"question\": \"How tall is Mount Everest?\",\n",
        "        \"expected_answer\": \"8,848 meters\"\n",
        "    }\n",
        "]\n",
        "\n",
        "while True:\n",
        "    context = input(\"Enter a context: \")\n",
        "    question = input(\"Enter a question: \")\n",
        "\n",
        "    answer = answer_question(question, context, model)\n",
        "    print()\n",
        "    print(f\"Context: {context}\")\n",
        "    print(f\"Question: {question}\")\n",
        "    print(f\"Answer: {answer}\")\n",
        "    print()\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "ez40XRilYyfo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}