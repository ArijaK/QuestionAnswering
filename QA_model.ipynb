{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "2bB3MZnaPMzh"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArijaK/QuestionAnswering/blob/main/QA_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question Answering Model**\n",
        "\n",
        "The code below (data preparation and evaluation) is based on Hugging Face *Question answering* examples, availabe [here (chapter)](https://huggingface.co/learn/nlp-course/chapter7/7?fw=pt) and [here (notebook)](https://github.com/huggingface/notebooks/blob/main/examples/question_answering.ipynb).\n",
        "\n"
      ],
      "metadata": {
        "id": "tFK-I144_hN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "id": "EtKtEAx7QLHE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49fda124-6dd2-45ae-d6e8-78d969f28e7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.3.0+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.31.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.5.40)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flags.\n",
        "# Data preprocessing.\n",
        "DATASET = 'squad_v2'\n",
        "MODEL_CHECKPOINT = 'albert-base-v2'\n",
        "# Maximum length of a feature (question and context).\n",
        "MAX_LENGTH = 384\n",
        "# Number of overlapping tokens.\n",
        "STRIDE = 128\n",
        "# Fine-tuning.\n",
        "TRAIN = False\n",
        "# Evaluation.\n",
        "N_BEST = 50\n",
        "# Usually sentences do not exceed this length.\n",
        "MAX_ANSWER_LENGTH = 40\n",
        "# Path to fine-tuned model.\n",
        "USE_SAVED = True\n",
        "MODEL_PATH = 'drive/MyDrive/Colab Notebooks/Fine-tuned_models/albert-base-v2-squadv2'"
      ],
      "metadata": {
        "id": "nafn_dQy0lc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation"
      ],
      "metadata": {
        "id": "2bB3MZnaPMzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Easy way to load the dataset.\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(DATASET)\n",
        "dataset"
      ],
      "metadata": {
        "id": "cjWZV2frx8YH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24444292-ddc0-467b-d63b-33841c8bdcb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 130319\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 11873\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing.\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)"
      ],
      "metadata": {
        "id": "4-hMCQB44cN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if a fast tokenizer is implemented.\n",
        "assert tokenizer.is_fast"
      ],
      "metadata": {
        "id": "Y5mF2cathDwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the tokenizer on a simple example.\n",
        "inputs = tokenizer('Where can I buy cat food?', 'Cat food is sold in all pet stores. You can buy cat food online too.')\n",
        "tokenizer.decode(inputs['input_ids'])"
      ],
      "metadata": {
        "id": "doHPtjGA9mNh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe35ed23-4492-4b87-90ea-714f3ef5dc72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] where can i buy cat food?[SEP] cat food is sold in all pet stores. you can buy cat food online too.[SEP]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_train_data(data):\n",
        "  # Remove leading and trailing whitespaces.\n",
        "  data['question'] = [q.strip() for q in data['question']]\n",
        "\n",
        "  inputs = tokenizer(\n",
        "      data['question'],\n",
        "      data['context'],\n",
        "      truncation='only_second',\n",
        "      max_length=MAX_LENGTH,\n",
        "      stride=STRIDE,\n",
        "      return_overflowing_tokens=True,\n",
        "      return_offsets_mapping=True,\n",
        "      padding='max_length',\n",
        "  )\n",
        "\n",
        "  # Map from a feature to its corresponding dataset sample.\n",
        "  sample_mapping = inputs.pop('overflow_to_sample_mapping')\n",
        "  # Map from token to character position in the original context.\n",
        "  offset_mapping = inputs.pop('offset_mapping')\n",
        "\n",
        "  inputs['start_positions'] = []\n",
        "  inputs['end_positions'] = []\n",
        "\n",
        "  for i, offsets in enumerate(offset_mapping):\n",
        "    input_ids = inputs['input_ids'][i]\n",
        "    # For no answer.\n",
        "    cls_index = input_ids.index(tokenizer.cls_token_id)\n",
        "\n",
        "    sequence_ids = inputs.sequence_ids(i)\n",
        "    sample_index = sample_mapping[i]\n",
        "    answer = data['answers'][sample_index]\n",
        "\n",
        "    if len(answer['answer_start']) == 0:\n",
        "      inputs['start_positions'].append(cls_index)\n",
        "      inputs['end_positions'].append(cls_index)\n",
        "    else:\n",
        "      start_char = answer['answer_start'][0]\n",
        "      end_char = start_char + len(answer['text'][0])\n",
        "\n",
        "      # Find the start and end of the current feature's context in the sample text.\n",
        "      token_start_index = 0\n",
        "      while sequence_ids[token_start_index] != 1:\n",
        "        token_start_index += 1\n",
        "\n",
        "      token_end_index = len(input_ids) - 1\n",
        "      while sequence_ids[token_end_index] != 1:\n",
        "        token_end_index -= 1\n",
        "\n",
        "      # If the answer is out of the current feature's context.\n",
        "      if not(offsets[token_start_index][0] <= start_char and\n",
        "             offsets[token_end_index][1] >= end_char):\n",
        "        inputs['start_positions'].append(cls_index)\n",
        "        inputs['end_positions'].append(cls_index)\n",
        "      else:\n",
        "        # Find tokens that correspond to the start and end of the answer.\n",
        "        while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
        "          token_start_index += 1\n",
        "        inputs['start_positions'].append(token_start_index - 1)\n",
        "        while offsets[token_end_index][1] >= end_char:\n",
        "          token_end_index -= 1\n",
        "        inputs['end_positions'].append(token_end_index + 1)\n",
        "\n",
        "  return inputs"
      ],
      "metadata": {
        "id": "UqafycX5Bxxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if function works as expected.\n",
        "result = preprocess_train_data(dataset['train'][:1])\n",
        "print(tokenizer.decode(result['input_ids'][0][result['start_positions'][0]: result['end_positions'][0]+1]))\n",
        "print(dataset['train'][0]['answers']['text'][0])"
      ],
      "metadata": {
        "id": "tMi1pre0kLXi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53ffce50-5a48-47f9-9058-550a0b2df666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in the late 1990s\n",
            "in the late 1990s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = dataset['train'].map(\n",
        "    preprocess_train_data,\n",
        "    batched=True,\n",
        "    remove_columns=dataset['train'].column_names,\n",
        ")\n",
        "len(dataset['train']), len(tokenized_dataset)"
      ],
      "metadata": {
        "id": "vHcv1wbUSnwy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe2189d6-44d2-4a31-d528-db1afef27bd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(130319, 131958)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing.\n",
        "def preprocess_validation_data(data):\n",
        "  data['question'] = [q.strip() for q in data['question']]\n",
        "\n",
        "  inputs = tokenizer(\n",
        "      data['question'],\n",
        "      data['context'],\n",
        "      truncation='only_second',\n",
        "      max_length=MAX_LENGTH,\n",
        "      stride=STRIDE,\n",
        "      return_overflowing_tokens=True,\n",
        "      return_offsets_mapping=True,\n",
        "      padding='max_length',\n",
        "  )\n",
        "\n",
        "  # Map from a feature to its corresponding dataset sample.\n",
        "  sample_mapping = inputs.pop('overflow_to_sample_mapping')\n",
        "  inputs['example_ids'] = []\n",
        "\n",
        "  for i in range(len(inputs['input_ids'])):\n",
        "    sample_index = sample_mapping[i]\n",
        "    inputs['example_ids'].append(data['id'][sample_index])\n",
        "\n",
        "    # Set the question part offsets to None, to easily determine the context part.\n",
        "    sequence_ids = inputs.sequence_ids(i)\n",
        "    inputs['offset_mapping'][i] = [\n",
        "        (o if sequence_ids[k] == 1 else None)\n",
        "        for k, o in enumerate(inputs['offset_mapping'][i])\n",
        "    ]\n",
        "\n",
        "  return inputs"
      ],
      "metadata": {
        "id": "-P_VXBdGugPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_dataset = dataset['validation'].map(\n",
        "    preprocess_validation_data,\n",
        "    batched=True,\n",
        "    remove_columns=dataset['validation'].column_names,\n",
        ")\n",
        "len(dataset['validation']), len(validation_dataset)"
      ],
      "metadata": {
        "id": "hjhmNM-MLEMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b68b3d54-4419-4e89-d40c-0a40c5bc293f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11873, 12171)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning\n",
        "\n",
        "Our fine-tuned models can be found in Google Drive shared folder [here](https://drive.google.com/drive/folders/1LjE8UzVeHCNoYPd6U9t-OrV2EDBeqR8W?usp=sharing)."
      ],
      "metadata": {
        "id": "fdi_MkNtX7DB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "SBazHdROmsje",
        "outputId": "e7310d77-ad36-4067-f762-224e99223bd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "nndUgR0qBx8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments, AutoModelForQuestionAnswering\n",
        "\n",
        "# Use already fine-tuned models instead of fine-tuning one.\n",
        "if USE_SAVED:\n",
        "  model = model = AutoModelForQuestionAnswering.from_pretrained(MODEL_PATH)\n",
        "else:\n",
        "  model = AutoModelForQuestionAnswering.from_pretrained(MODEL_CHECKPOINT)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    fp16=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model.to(device),\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    eval_dataset=validation_dataset,\n",
        ")"
      ],
      "metadata": {
        "id": "Mq6b9zjHYAGt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "outputId": "5a0f8ceb-7095-43d8-82ac-4b906fd6f777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Incorrect path_or_model_id: 'drive/MyDrive/Colab Notebooks/Fine-tuned_models/albert-base-v2-squadv2'. Please provide either the path to a local folder or the repo_id of a model on the Hub.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    400\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrepo_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;34m\"Repo id must be in the form 'repo_name' or 'namespace/repo_name':\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'drive/MyDrive/Colab Notebooks/Fine-tuned_models/albert-base-v2-squadv2'. Use `repo_type` argument if needed.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-3d886a5afaa5>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Use already fine-tuned models instead of fine-tuning one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mUSE_SAVED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForQuestionAnswering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForQuestionAnswering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_CHECKPOINT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m                 \u001b[0;31m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    485\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m                     \u001b[0mCONFIG_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"There was a specific connection error when trying to load {path_or_repo_id}:\\n{err}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHFValidationError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    464\u001b[0m             \u001b[0;34mf\"Incorrect path_or_model_id: '{path_or_repo_id}'. Please provide either the path to a local folder or the repo_id of a model on the Hub.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         ) from e\n",
            "\u001b[0;31mOSError\u001b[0m: Incorrect path_or_model_id: 'drive/MyDrive/Colab Notebooks/Fine-tuned_models/albert-base-v2-squadv2'. Please provide either the path to a local folder or the repo_id of a model on the Hub."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if TRAIN:\n",
        "  trainer.train()"
      ],
      "metadata": {
        "id": "NCfb_vA-YDnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if TRAIN:\n",
        "  trainer.save_model(MODEL_CHECKPOINT+'-squadv2')"
      ],
      "metadata": {
        "id": "ona_D_t8Z9nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "WGqLuKUtuIKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_predictions = trainer.predict(validation_dataset)"
      ],
      "metadata": {
        "id": "MGLGslSVheri",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "8f1f2611-adc1-4019-87cf-e5657cc11b56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'trainer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-999dc034e3a0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get back `example_ids` and `offset_mapping` column.\n",
        "validation_dataset.set_format(type=validation_dataset.format['type'], columns=list(validation_dataset.features.keys()))"
      ],
      "metadata": {
        "id": "ylY3JYFt0GZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def postprocess_predictions(raw_predictions, features, examples):\n",
        "  all_start_logits, all_end_logits = raw_predictions\n",
        "  features_per_example = collections.defaultdict(list)\n",
        "  for i, feature in enumerate(features):\n",
        "    features_per_example[feature['example_ids']].append(i)\n",
        "\n",
        "  predictions = collections.OrderedDict()\n",
        "  for example in tqdm(examples):\n",
        "    example_id = example['id']\n",
        "    context = example['context']\n",
        "\n",
        "    # Score of the impossible answer for the example.\n",
        "    min_null_score = None\n",
        "    answers = []\n",
        "\n",
        "    for feature_index in features_per_example[example_id]:\n",
        "      start_logit = all_start_logits[feature_index]\n",
        "      end_logit = all_end_logits[feature_index]\n",
        "      offset_mapping = features[feature_index]['offset_mapping']\n",
        "\n",
        "      cls_index = features[feature_index]['input_ids'].index(tokenizer.cls_token_id)\n",
        "      feature_null_score = start_logit[cls_index] + end_logit[cls_index]\n",
        "\n",
        "      if min_null_score is None or min_null_score < feature_null_score:\n",
        "        min_null_score = feature_null_score\n",
        "\n",
        "      start_indexes = np.argsort(start_logit)[-1: -N_BEST - 1 : -1].tolist()\n",
        "      end_indexes = np.argsort(end_logit)[-1: -N_BEST - 1 : -1].tolist()\n",
        "      for start_index in start_indexes:\n",
        "        for end_index in end_indexes:\n",
        "          if (start_index >= len(offset_mapping)\n",
        "              or end_index >= len(offset_mapping)\n",
        "              or offset_mapping[start_index] is None\n",
        "              or offset_mapping[end_index] is None\n",
        "          ):\n",
        "            continue\n",
        "          if end_index < start_index or end_index-start_index+1>MAX_ANSWER_LENGTH:\n",
        "            continue\n",
        "\n",
        "          start_char = offset_mapping[start_index][0]\n",
        "          end_char = offset_mapping[end_index][1]\n",
        "          answers.append({\n",
        "              'text': context[start_char : end_char],\n",
        "              'logit_score': start_logit[start_index] + end_logit[end_index],\n",
        "          })\n",
        "\n",
        "    if len(answers) > 0:\n",
        "      best_answer = max(answers, key=lambda x: x['logit_score'])\n",
        "    else:\n",
        "      best_answer = {'text': '', 'logit_score': 0.0}\n",
        "\n",
        "    answer = best_answer['text'] if best_answer['logit_score'] > min_null_score else ''\n",
        "    predictions[example_id] = answer\n",
        "\n",
        "  return predictions\n"
      ],
      "metadata": {
        "id": "tpp1TirLaWdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = postprocess_predictions(raw_predictions.predictions, validation_dataset, dataset['validation'])"
      ],
      "metadata": {
        "id": "qNxVq1_WqN4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Save predictions as json file.\n",
        "with open(\"predictions.json\", \"w\") as json_file:\n",
        "    json.dump(predictions, json_file)"
      ],
      "metadata": {
        "id": "sdHu_TFD0uq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "metric = load_metric(DATASET, trust_remote_code=True)\n",
        "formatted_predictions = [{'id': k, 'prediction_text': v, 'no_answer_probability': 0.0} for k, v in predictions.items()]\n",
        "theoretical_answers = [{'id': ex['id'], 'answers': ex['answers']} for ex in dataset['validation']]\n",
        "metric.compute(predictions=formatted_predictions, references=theoretical_answers)"
      ],
      "metadata": {
        "id": "rost4nPAtF7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "VXmUvENmQRtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "CMOe-QUCpewq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_question(question, context, model):\n",
        "    inputs = tokenizer(question, context, return_tensors='pt', truncation=True, max_length=512)\n",
        "\n",
        "    outputs = model(**inputs.to(device))\n",
        "\n",
        "    # Get the most likely start and end tokens\n",
        "    start_scores = outputs.start_logits\n",
        "    end_scores = outputs.end_logits\n",
        "    start_index = torch.argmax(start_scores)\n",
        "    end_index = torch.argmax(end_scores) + 1\n",
        "\n",
        "    # Get score for no answer case\n",
        "    no_answer_score = start_scores[0][0].item() + end_scores[0][0].item()\n",
        "\n",
        "    # Check if the predicted span is valid and is not no answer case\n",
        "    max_start_score = start_scores[0][start_index].item()\n",
        "    max_end_score = end_scores[0][end_index - 1].item()\n",
        "    if start_index < len(inputs.input_ids[0]) and end_index <= len(inputs.input_ids[0]) and (max_start_score + max_end_score) > no_answer_score:\n",
        "        answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs.input_ids[0][start_index:end_index]))\n",
        "    else:\n",
        "        answer = \"No answer\"\n",
        "\n",
        "    return answer"
      ],
      "metadata": {
        "id": "YO5e--khm8OZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# some test cases for demonstration\n",
        "test_cases = [\n",
        "    {\n",
        "        \"context\": \"The Eiffel Tower is located in Paris.\",\n",
        "        \"question\": \"Where is the Eiffel Tower located?\",\n",
        "        \"expected_answer\": \"Paris\"\n",
        "    },\n",
        "    {\n",
        "        \"context\": \"Albert Einstein developed the theory of relativity.\",\n",
        "        \"question\": \"Who developed the theory of relativity?\",\n",
        "        \"expected_answer\": \"Albert Einstein\"\n",
        "    },\n",
        "    {\n",
        "        \"context\": \"The Declaration of Independence was signed in 1776.\",\n",
        "        \"question\": \"When was the Declaration of Independence signed?\",\n",
        "        \"expected_answer\": \"1776\"\n",
        "    },\n",
        "    {\n",
        "        \"context\": \"Water boils at 100 degrees Celsius.\",\n",
        "        \"question\": \"What is the capital of Australia?\",\n",
        "        \"expected_answer\": \"No answer\"\n",
        "    },\n",
        "    {\n",
        "        \"context\": \"The Great Wall of China is a series of fortifications that were built across the northern borders of China to protect and consolidate territories of Chinese states and empires against various nomadic groups of the steppe and their polities. Several walls were being built as early as the 7th century BC; these, later joined together and made bigger and stronger, are now collectively referred to as the Great Wall.\",\n",
        "        \"question\": \"Where is the Great Wall located?\",\n",
        "        \"expected_answer\": \"7th century BC\"\n",
        "    },\n",
        "    {\n",
        "        \"context\": \"Despite being a well-known physicist, Isaac Newton also made significant contributions to mathematics, including the development of calculus.\",\n",
        "        \"question\": \"What did Isaac Newton develop in mathematics?\",\n",
        "        \"expected_answer\": \"calculus\"\n",
        "    },\n",
        "    {\n",
        "        \"context\": \"Amazon was founded by Jeff Bezos in 1994. Initially started as an online bookstore, it has since expanded to a wide variety of products and services.\",\n",
        "        \"question\": \"Who founded Amazon?\",\n",
        "        \"expected_answer\": \"Jeff Bezos\"\n",
        "    },\n",
        "    {\n",
        "        \"context\": \"Marie Curie was a physicist and chemist who conducted pioneering research on radioactivity. She was the first woman to win a Nobel Prize.\",\n",
        "        \"question\": \"Who was the first woman to win a Nobel Prize?\",\n",
        "        \"expected_answer\": \"Marie Curie\"\n",
        "    },\n",
        "    {\n",
        "        \"context\": \"Paris is a major European city and a global center for art, fashion, gastronomy, and culture. It is the capital of France.\",\n",
        "        \"question\": \"What is Paris known for?\",\n",
        "        \"expected_answer\": \"art, fashion, gastronomy, and culture\"\n",
        "    },\n",
        "    {\n",
        "        \"context\": \"Mount Everest is 8,848 meters tall.\",\n",
        "        \"question\": \"How tall is Mount Everest?\",\n",
        "        \"expected_answer\": \"8,848 meters\"\n",
        "    }\n",
        "]\n",
        "\n",
        "while True:\n",
        "    context = input(\"Enter a context: \")\n",
        "    question = input(\"Enter a question: \")\n",
        "\n",
        "    answer = answer_question(question, context, model)\n",
        "    print()\n",
        "    print(f\"Context: {context}\")\n",
        "    print(f\"Question: {question}\")\n",
        "    print(f\"Answer: {answer}\")\n",
        "    print()\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "ez40XRilYyfo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}